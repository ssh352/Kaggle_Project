y = getinfo(dtrain, "label")
err= mae(exp(y),exp(yhat) )
return (list(metric = "error", value = err))
}
res = xgb.cv(xgb_params,
dtrain,
nrounds=750,
nfold=4,
early_stopping_rounds=15,
print_every_n = 10,
verbose= 1,
feval=xg_eval_mae,
maximize=FALSE)
best_nrounds = which(res$test.error.mean == min(res$test.error.mean))
best_nrounds = res$best_iteration
cv_mean = res$evaluation_log$test_error_mean[best_nrounds]
cv_std = res$evaluation_log$test_error_std[best_nrounds]
cat(paste0('CV-Mean: ',cv_mean,' ', cv_std))
gbdt = xgb.train(xgb_params, dtrain, best_nrounds)
submission = fread(SUBMISSION_FILE, colClasses = c("integer", "numeric"))
submission$loss = exp(predict(gbdt,dtest))
write.csv(submission,'xgb_starter_v2.hehehe.csv',row.names = FALSE)
setwd("D:/Dropbox/NYC DS Academy/Statistics/class 10 Neural Net/[14] Neural Networks Lecture Code")
concrete = read.csv("[14] Concrete.csv")
str(concrete)
summary(concrete)
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
install.packages("neuralnet")
concrete_norm = as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
concrete_train = concrete_norm[1:773, ]
concrete_test = concrete_norm[774:1030, ]
nrow(concrete_train)/nrow(concrete_norm)
nrow(concrete_test)/nrow(concrete_norm)
library(neuralnet)
set.seed(0)
concrete_model = neuralnet(strength ~ cement + slag +     #Cannot use the shorthand
ash + water + superplastic + #dot (.) notation.
coarseagg + fineagg + age,
hidden = 1, #Default number of hidden neurons.
data = concrete_train)
plot(concrete_model)
str(concrete_train)
model_results = compute(concrete_model, concrete_test[, 1:8])
predicted_strength = model_results$net.result
cor(predicted_strength, concrete_test$strength)
plot(predicted_strength, concrete_test$strength)
set.seed(0)
concrete_model2 = neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
hidden = 5,
data = concrete_train)
plot(concrete_model)
plot(concrete_model2)
model_results2 = compute(concrete_model2, concrete_test[, 1:8])
predicted_strength2 = model_results2$net.result
cor(predicted_strength2, concrete_test$strength)
plot(predicted_strength2, concrete_test$strength)
cor(predicted_strength2, concrete_test$strength)
plot(predicted_strength2, concrete_test$strength)
plot(predicted_strength2, concrete_test$strength)
plot(predicted_strength2, concrete_test$strength)
set.seed(0)
concrete_model3 = neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
hidden = c(15, 3, 4),
data = concrete_train)
plot(concrete_model3)
model_results3 = compute(concrete_model3, concrete_test[, 1:8])
predicted_strength3 = model_results3$net.result
cor(predicted_strength3, concrete_test$strength)
plot(predicted_strength3, concrete_test$strength)
plot(predicted_strength3, concrete_test$strength)
plot(predicted_strength3, concrete_test$strength)
plot(concrete_model3)
summary(concrete_model3)
concrete_model3
concrete_model3$net.result
concrete_model3$response
concrete_model3$covariate
concrete_model3$model.list
concrete_model3$err.fct()
concrete_model3$linear.output
concrete_model3$weights
concrete_model3$result.matrix
set.seed(0)
concrete_model3 = neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
hidden = c(15, 3, 4),
data = concrete_train)
plot(concrete_model3)
plot(concrete_model3)
setwd("C:/Users/Xinyuan Wu/Desktop/Xinyuan's Repo/Kaggle_Project")
train <- read.csv("data/train.csv/train.csv")
num <- train[, -c(1: 117, 132)]
length(unique(num$cont1))
?sort
sort(unique(num$cont1), decreasing = False)
sort(unique(num$cont1), decreasing = FALSE)
plot(1:647, sort(unique(num$cont1), decreasing = FALSE))
length(unique(num$cont1))
length(unique(num$cont2))
length(unique(num$cont3))
length(unique(num$cont4))
plot(1:33, sort(unique(num$cont2), decreasing = FALSE))
plot(1:76, sort(unique(num$cont3), decreasing = FALSE))
plot(1:112, sort(unique(num$cont4), decreasing = FALSE))
sapply(num, function(x) length(unique(x)))
str(num)
draw_cont <- function(col) {
len <- sapply(num, function(x) length(unique(x)))
plot(1:len[col], sort(unique(num[, col]), decreasing = FALSE))
}
draw_cont(1)
draw_cont(2)
draw_cont(3)
draw_cont(4)
draw_cont(5)
draw_cont(6)
draw_cont(7)
draw_cont(8)
draw_cont(9)
draw_cont(10)
draw_cont(11)
draw_cont(12)
draw_cont(13)
draw_cont(14)
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(i)
}
draw_cont <- function(col) {
len <- sapply(num, function(x) length(unique(x)))
plot(1:len[col], sort(unique(num[, col]), decreasing = FALSE),
xlab = col, ylab = "Value")
}
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(i)
}
install.packages("caret")
?paste
draw_cont <- function(col) {
len <- sapply(num, function(x) length(unique(x)))
plot(1:len[col], sort(unique(num[, col]), decreasing = FALSE),
xlab = paste0('Cont', col), ylab = "Value")
}
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(i)
}
?replace
a <- 1:100
b <- seq(0, 1, 100)
a
b
b <- seq(0, 1, len = 100)
b
replace(b, a)
replace(b, values = a)
replace(b, list = 100:1, values = a)
?sort
sort(unique(num[, 1], index.return = TRUE)
)
sort(num[, 1], index.return = TRUE)
length(unique(sort(num[, 1], index.return = TRUE)))
unique(sort(num[, 1], index.return = TRUE))
length(unique(sort(num[, 1], index.return = TRUE)))
length(unique(sort(num[, 1], index.return = TRUE))[[2]])
length(unique(sort(num[, 1], index.return = TRUE))[[1]])
replace(b, values = a)
a <- factor(num$cont1)
head(levels(a))
a <- factor(num$cont2)
a
a <- factor(num$cont2, levels = num$cont2[sort.int(num$cont2, decreasing = FALSE, index.return = TRUE)[[2]]])
levels(a)
a <- factor(num$cont2, levels = num$cont2[sort.int(num$cont2, decreasing = FALSE, index.return = TRUE)[[2]]])
a <- factor(num$cont2, levels = sort(unique(num[, cont2]), decreasing = FALSE))
a <- factor(num$cont2, levels = sort(unique(num[, 'cont2']), decreasing = FALSE))
levels(a)
levels(a) <- 1:33
a
back_trans <- function() {
for (i in 1:14) {
a <- factor(num[, i],
levels = sort(unique(num[, i]), decreasing = FALSE))
levels(a) <- 1:length(unique(num[, i]))
num[, i] <- as.numeric(as.character(a))
}
}
back_trans()
str(num)
str(back_trans())
str(back_trans())
back_trans <- function(data = num) {
for (i in 1:14) {
a <- factor(num[, i],
levels = sort(unique(num[, i]), decreasing = FALSE))
levels(a) <- 1:length(unique(num[, i]))
num[, i] <- as.numeric(as.character(a))
}
return(num)
}
str(back_trans())
num_trans <- back_trans()
draw_cont <- function(data = num, col) {
len <- sapply(data, function(x) length(unique(x)))
plot(1:len[col], sort(unique(data[, col]), decreasing = FALSE),
xlab = paste0('Cont', col), ylab = "Value")
}
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(num, i)
}
draw_cont <- function(data = num, col) {
len <- sapply(data, function(x) length(unique(x)))
plot(1:len[col], sort(unique(data[, col]), decreasing = FALSE),
xlab = paste0('Cont', col), ylab = "Value")
}
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(col = i)
}
set.seed(0)
x1 = c(rnorm(100, 0, 4), rnorm(100, 1, 3))
x2 = c(rnorm(100, 0, 1), rnorm(100, 6, 1))
y = as.factor(c(rep(-1, 100), rep(1, 100)))
y
linearly.separable = data.frame(x1, x2, y)
plot(linearly.separable$x1, linearly.separable$x2, col = linearly.separable$y)
library(e1071)
plot(linearly.separable$x1, linearly.separable$x2, col = linearly.separable$y)
set.seed(0)
train.index = sample(1:200, 200*.8)
test.index = -train.index
svm.mmc.linear = svm(y ~ ., #Familiar model fitting notation.
data = linearly.separable, #Using the linearly separable data.
subset = train.index, #Using the training data.
kernel = "linear", #Using a linear kernel.
cost = 1e6) #A very large cost; default is 1.
str(back_trans)
str(back_trans())
plot(svm.mmc.linear, linearly.separable[train.index, ])
summary(svm.mmc.linear)
svm.mmc.linear$index
ypred = predict(svm.mmc.linear, linearly.separable[test.index, ])
table("Predicted Values" = ypred, "True Values" = linearly.separable[test.index, "y"])
linearly.separable2 = rbind(linearly.separable, c(-5, 3, 1))
plot(linearly.separable2$x1, linearly.separable2$x2, col = linearly.separable2$y)
svm.mmc.linear2 = svm(y ~ .,
data = linearly.separable2,
kernel = "linear",
cost = 1e6)
plot(svm.mmc.linear, linearly.separable[train.index, ]) #Old model.
plot(svm.mmc.linear2, linearly.separable2) #New model.
summary(svm.mmc.linear2)
svm.mmc.linear2$index
svm.svc.linear2 = svm(y ~ .,
data = linearly.separable2,
kernel = "linear",
cost = 1)
plot(svm.svc.linear2, linearly.separable2)
summary(svm.svc.linear2)
svm.svc.linear2$index
svm.svc.linear3 = svm(y ~ .,
data = linearly.separable2,
kernel = "linear",
cost = .1)
plot(svm.svc.linear3, linearly.separable2)
summary(svm.svc.linear3)
svm.svc.linear3$index
set.seed(0)
x1 = c(rnorm(100, -1, 1), rnorm(100, 1, 1))
x2 = c(rnorm(100, -1, 1), rnorm(100, 1, 1))
y = as.factor(c(rep(-1, 100), rep(1, 100)))
overlapping = data.frame(x1, x2, y)
plot(overlapping$x1, overlapping$x2, col = overlapping$y)
set.seed(0)
cv.svm.overlapping = tune(svm,
y ~ .,
data = overlapping[train.index, ],
kernel = "linear",
ranges = list(cost = 10^(seq(-5, .5, length = 100))))
summary(cv.svm.overlapping)
summary(cv.svm.overlapping)
plot(cv.svm.overlapping$performances$cost,
cv.svm.overlapping$performances$error,
xlab = "Cost",
ylab = "Error Rate",
type = "l")
best.overlapping.model = cv.svm.overlapping$best.model
summary(best.overlapping.model)
ypred = predict(best.overlapping.model, overlapping[test.index, ])
table("Predicted Values" = ypred, "True Values" = overlapping[test.index, "y"])
svm.best.overlapping = svm(y ~ .,
data = overlapping,
kernel = "linear",
cost = best.overlapping.model$cost)
plot(svm.best.overlapping, overlapping)
summary(svm.best.overlapping)
svm.best.overlapping$index
ypred = predict(svm.best.overlapping, overlapping)
table("Predicted Values" = ypred, "True Values" = overlapping[, "y"])
set.seed(0)
x1 = c(rnorm(100, 2), rnorm(100, -2), rnorm(100))
x2 = c(rnorm(100, 2), rnorm(100, -2), rnorm(100))
y = as.factor(c(rep(-1, 200), rep(1, 100)))
nonlinear = data.frame(x1, x2, y)
plot(nonlinear$x1, nonlinear$x2, col = nonlinear$y)
svm.radial = svm(y ~ .,
data = nonlinear,
kernel = "radial",
cost = 1,
gamma = .5) #Default is 1/p.
plot(svm.radial, nonlinear)
summary(svm.radial)
svm.radial$index
svm.radial.smallgamma = svm(y ~ .,
data = nonlinear,
kernel = "radial",
cost = 1,
gamma = .05)
plot(svm.radial.smallgamma, nonlinear)
summary(svm.radial.smallgamma)
svm.radial.smallgamma$index
svm.radial.largegamma = svm(y ~ .,
data = nonlinear,
kernel = "radial",
cost = 1,
gamma = 10)
plot(svm.radial.largegamma, nonlinear)
summary(svm.radial.largegamma)
svm.radial.largegamma$index
set.seed(0)
train.index = sample(1:300, 300*.8)
test.index = -train.index
set.seed(0)
cv.svm.radial = tune(svm,
y ~ .,
data = nonlinear[train.index, ],
kernel = "radial",
ranges = list(cost = 10^(seq(-1, 1.5, length = 20)),
gamma = 10^(seq(-2, 1, length = 20))))
install.packages("rgl")
summary(cv.svm.radial)
library(rgl)
plot3d(cv.svm.radial$performances$cost,
cv.svm.radial$performances$gamma,
cv.svm.radial$performances$error,
xlab = "Cost",
ylab = "Gamma",
zlab = "Error",
type = "s",
size = 1)
best.nonlinear.model = cv.svm.radial$best.model
summary(best.nonlinear.model)
ypred = predict(best.nonlinear.model, nonlinear[test.index, ])
table("Predicted Values" = ypred, "True Values" = nonlinear[test.index, "y"])
x1 = c(rnorm(100, 2), rnorm(100, -2), rnorm(100), rnorm(100, 2))
x2 = c(rnorm(100, 2), rnorm(100, -2), rnorm(100), rnorm(100, -2))
y = as.factor(c(rep(-1, 200), rep(1, 100), rep(2, 100)))
multi = data.frame(x1, x2, y)
plot(multi$x1, multi$x2, col = multi$y)
set.seed(0)
train.index = sample(1:400, 400*.8)
test.index = -train.index
set.seed(0)
cv.multi = tune(svm,
y ~ .,
data = multi[train.index, ],
kernel = "radial",
ranges = list(cost = 10^(seq(-1, 1.5, length = 20)),
gamma = 10^(seq(-2, 1, length = 20))))
summary(cv.multi)
plot3d(cv.multi$performances$cost,
cv.multi$performances$gamma,
cv.multi$performances$error,
xlab = "Cost",
ylab = "Gamma",
zlab = "Error",
type = "s",
size = 1)
best.multi.model = cv.multi$best.model
summary(best.multi.model)
ypred = predict(best.multi.model, multi[test.index, ])
table("Predicted Values" = ypred, "True Values" = multi[test.index, "y"])
svm.best.multi = svm(y ~ .,
data = multi,
kernel = "radial",
cost = best.multi.model$cost,
gamma = best.multi.model$gamma)
plot(svm.best.multi, multi)
summary(svm.best.multi)
svm.best.multi$index
ypred = predict(svm.best.multi, multi)
table("Predicted Values" = ypred, "True Values" = multi[, "y"])
range(num)
num
sapply(num, range)
test <- read.csv("data/test.csv/test.csv")
str(test)
str(test, list.len = ncol(test))
num_test <- test[, -c(1:117)]
str(num_train); str(num_test)
num_train <- train[, -c(1: 117, 132)]
str(num_train); str(num_test)
suppressPackageStartupMessages(library(corrplot))
correlations <- cor(num_train)
corrplot(correlations, method = "square", order = "hclust")
corrplot(correlations, uppCI.mat = "square", order = "hclust")
corrplot(correlations, shape = "square", order = "hclust")
corrplot(correlations, method = "square", order = "hclust")
suppressPackageStartupMessages(library(corrplot))
correlations <- cor(num_train)
corrplot(correlations, method = "square", order = "hclust")
draw_cont <- function(data = num_train, col) {
len <- sapply(data, function(x) length(unique(x)))
plot(1:len[col], sort(unique(data[, col]), decreasing = FALSE),
xlab = paste0('Cont', col), ylab = "Value")
}
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(num_train, col = i)
}
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(num_test, col = i)
}
par(mfrow = c(6, 5))
for (i in 1:14) {
draw_cont(num_train, col = i)
draw_cont(num_test, col = i)
}
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(num_train, col = i)
}
par(mfrow = c(6, 5))
for (i in 1:14) {
draw_cont(num_train, col = i)
draw_cont(num_test, col = i)
}
par(mfrow = c(6, 5))
for (i in 1:14) {
draw_cont(num_train, col = i)
draw_cont(num_test, col = i)
}
set.seed(0)
cv.svm.radial = tune(svm,
y ~ .,
data = nonlinear[train.index, ],
kernel = "radial",
ranges = list(cost = 10^(seq(-1, 1.5, length = 20)),
gamma = 10^(seq(-2, 1, length = 20))))
par(mfrow = c(3, 5))
for (i in 1:7) {
draw_cont(num_train, col = i)
draw_cont(num_test, col = i)
}
par(mfrow = c(3, 5))
for (i in 8:14) {
draw_cont(num_train, col = i)
draw_cont(num_test, col = i)
}
draw_cont <- function(data, col) {
len <- sapply(data, function(x) length(unique(x)))
plot(1:len[col], sort(unique(data[, col]), decreasing = FALSE),
xlab = paste0('Cont', col), ylab = "Value")
}
par(mfrow = c(3, 5))
for (i in 1:14) {
draw_cont(num_train, col = i)
}
par(mfrow = c(3, 5))
for (i in 1:7) {
draw_cont(num_train, col = i)
draw_cont(num_test, col = i)
}
par(mfrow = c(3, 5))
for (i in 8:14) {
draw_cont(num_train, col = i)
draw_cont(num_test, col = i)
}
back_trans <- function(data) {
for (i in 1:14) {
a <- factor(data[, i],
levels = sort(unique(data[, i]), decreasing = FALSE))
levels(a) <- 1:length(unique(data[, i]))
data[, i] <- as.numeric(as.character(a))
}
return(data)
}
back_trans <- function(data) {
for (i in 1:dim(data)[2]) {
a <- factor(data[, i],
levels = sort(unique(data[, i]), decreasing = FALSE))
levels(a) <- 1:length(unique(data[, i]))
data[, i] <- as.numeric(as.character(a))
}
return(data)
}
num_trans <- back_trans(num_train)
num_test_trans <- back_trans(num_test)
num_train_trans <- back_trans(num_train)
str(num_train_trans)
str(num_test_trans)
